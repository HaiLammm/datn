# Epic 8 AI Sub-Agents - README

## ğŸ“‹ Tá»•ng quan

ÄÃ¢y lÃ  bá»™ 3 AI Sub-Agents Ä‘Æ°á»£c phÃ¡t triá»ƒn cho **Epic 8: Virtual AI Interview Room** trong há»‡ thá»‘ng AI Recruitment Platform (DATN). CÃ¡c agents cháº¡y trÃªn **Ollama** (self-hosted) vÃ  tÃ­ch há»£p vÃ o backend Python FastAPI.

### CÃ¡c Sub-Agents

1. **QuestionCraft AI** (Question Generator) â“
   - Táº¡o cÃ¢u há»i phá»ng váº¥n tá»« JD vÃ  CV
   - Model: llama3.2:3b-instruct-fp16
   - Latency: ~4s

2. **DialogFlow AI** (Conversation Agent) ğŸ’¬
   - Quáº£n lÃ½ cuá»™c há»™i thoáº¡i phá»ng váº¥n
   - ÄÃ¡nh giÃ¡ tá»«ng turn, táº¡o follow-up questions
   - Model:Human-Like-Qwen2.5-1.5B-Instruct
   - Latency: ~3s
   

3. **EvalMaster AI** (Performance Evaluator) ğŸ“Š
   - ÄÃ¡nh giÃ¡ tá»•ng thá»ƒ hiá»‡u suáº¥t phá»ng váº¥n
   - Táº¡o bÃ¡o cÃ¡o chi tiáº¿t vá»›i khuyáº¿n nghá»‹ tuyá»ƒn dá»¥ng
   - Model: llama3.2-uncensored
   - Latency: ~6s

## ğŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FastAPI Backend                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Question    â”‚  â”‚ Conversation â”‚  â”‚ Performance   â”‚ â”‚
â”‚  â”‚ Generator   â”‚  â”‚ Agent        â”‚  â”‚ Evaluator     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                   â”‚          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                          â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Ollama     â”‚
                    â”‚   Server     â”‚
                    â”‚ (localhost)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚            â”‚            â”‚
         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚ Llama   â”‚  â”‚ Qwen   â”‚  â”‚ Llama  â”‚
         â”‚ 3.2-3B  â”‚  â”‚ 2.5    â”‚  â”‚ 3.2-3B â”‚
         â”‚ (Q Gen) â”‚  â”‚ (Conv) â”‚  â”‚ (Eval) â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Cáº¥u trÃºc ThÆ° má»¥c

```
_sub-agents/
â”œâ”€â”€ agents/                      # Python implementation
â”‚   â”œâ”€â”€ base_agent.py           # Base class cho táº¥t cáº£ agents
â”‚   â”œâ”€â”€ question_generator.py   # QuestionCraft AI
â”‚   â”œâ”€â”€ conversation_agent.py   # DialogFlow AI
â”‚   â””â”€â”€ performance_evaluator.py # EvalMaster AI
â”‚
â”œâ”€â”€ configs/                     # JSON configurations
â”‚   â”œâ”€â”€ question_generator_config.json
â”‚   â”œâ”€â”€ conversation_agent_config.json
â”‚   â””â”€â”€ performance_evaluator_config.json
â”‚
â”œâ”€â”€ prompts/                     # System prompts
â”‚   â”œâ”€â”€ question_generator_prompt.txt
â”‚   â”œâ”€â”€ conversation_agent_prompt.txt
â”‚   â””â”€â”€ performance_evaluator_prompt.txt
â”‚
â”œâ”€â”€ api_examples/                # API request templates
â”‚   â”œâ”€â”€ question_generator_example.json
â”‚   â”œâ”€â”€ conversation_agent_example.json
â”‚   â””â”€â”€ performance_evaluator_example.json
â”‚
â”œâ”€â”€ samples/                     # Sample data for testing
â”‚   â”œâ”€â”€ sample_job_descriptions.md
â”‚   â”œâ”€â”€ sample_cvs.md
â”‚   â””â”€â”€ sample_interview_transcripts.md
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ test_base_agent.py
â”‚   â”œâ”€â”€ test_question_generator.py
â”‚   â”œâ”€â”€ test_conversation_agent.py
â”‚   â””â”€â”€ test_performance_evaluator.py
â”‚
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ INTEGRATION_GUIDE.md         # Backend integration guide
â”œâ”€â”€ TESTING_GUIDE.md             # Testing procedures
â””â”€â”€ PROMPT_TUNING.md             # Prompt customization guide
```

## ğŸš€ Quick Start

### 1. CÃ i Ä‘áº·t Ollama vÃ  Models

```bash
# Install Ollama (náº¿u chÆ°a cÃ³)
curl -fsSL https://ollama.com/install.sh | sh

# Pull models
ollama pull llama3.2:3b-instruct-fp16
ollama pull qwen2.5:1.5b-instruct-fp16

# Verify models
ollama list
```

### 2. CÃ i Ä‘áº·t Dependencies

```bash
# Install required Python packages
pip install requests  # For Ollama API calls

# Or add to requirements.txt
echo "requests>=2.31.0" >> requirements.txt
```

### 3. Test Agents

```python
# Test QuestionCraft AI
from _sub_agents.agents.question_generator import QuestionGeneratorAgent

agent = QuestionGeneratorAgent()
result = agent.generate_questions(
    job_description="Backend Developer vá»›i 2+ nÄƒm kinh nghiá»‡m Python...",
    cv_content="Nguyá»…n VÄƒn A, 3 nÄƒm kinh nghiá»‡m...",
    position_level="middle",
    num_questions=5
)

print(result)
```

### 4. TÃ­ch há»£p vÃ o FastAPI

Xem chi tiáº¿t trong `INTEGRATION_GUIDE.md`

## ğŸ¯ Use Cases

### Flow 1: Táº¡o CÃ¢u há»i Phá»ng váº¥n
```
1. HR táº¡o interview session má»›i
2. System gá»i QuestionCraft AI vá»›i JD + CV
3. Agent tráº£ vá» 10-15 cÃ¢u há»i phÃ¹ há»£p
4. HR review vÃ  chá»n cÃ¢u há»i (hoáº·c auto-select)
5. LÆ°u vÃ o database cho interview session
```

### Flow 2: Tiáº¿n hÃ nh Phá»ng váº¥n
```
1. Candidate join interview room
2. System hiá»ƒn thá»‹ cÃ¢u há»i Ä‘áº§u tiÃªn
3. Candidate tráº£ lá»i (text hoáº·c voice-to-text)
4. System gá»i DialogFlow AI Ä‘á»ƒ:
   - ÄÃ¡nh giÃ¡ cÃ¢u tráº£ lá»i
   - Quyáº¿t Ä‘á»‹nh next action (continue/follow-up/next)
5. Láº·p láº¡i cho Ä‘áº¿n háº¿t cÃ¢u há»i hoáº·c háº¿t thá»i gian
```

### Flow 3: ÄÃ¡nh giÃ¡ Káº¿t quáº£
```
1. Interview káº¿t thÃºc
2. System compile full transcript + turn evaluations
3. Gá»i EvalMaster AI Ä‘á»ƒ táº¡o comprehensive report
4. HR xem report vá»›i:
   - Overall score (0-10)
   - Dimension scores (Technical/Communication/Behavioral)
   - Hiring recommendation
   - Detailed analysis vá»›i evidence
5. HR quyáº¿t Ä‘á»‹nh final hiring decision
```

## âš™ï¸ Configuration

Má»—i agent cÃ³ file config JSON riÃªng:

```json
{
  "model": "llama3.2:3b-instruct-fp16",
  "model_parameters": {
    "temperature": 0.7,
    "top_p": 0.9,
    "num_predict": 2048
  },
  "ollama_settings": {
    "host": "http://localhost:11434",
    "timeout": 30
  },
  "performance_settings": {
    "target_latency_ms": 4000,
    "max_retries": 2
  }
}
```

Thay Ä‘á»•i cÃ¡c parameters Ä‘á»ƒ tune performance hoáº·c output quality.

## ğŸ“Š Performance

### Target Latency (P95)
- QuestionCraft AI: < 5s (generates 10 questions)
- DialogFlow AI: < 3s (per turn)
- EvalMaster AI: < 8s (full evaluation)

### Resource Requirements
- **RAM**: ~4GB cho Llama-3.2-3B, ~2GB cho Qwen2.5-1.5B
- **CPU**: 4+ cores recommended
- **Storage**: ~10GB total cho cáº£ 2 models

### Scaling
- Ollama há»— trá»£ concurrent requests (queue internally)
- CÃ³ thá»ƒ deploy multiple Ollama instances vá»›i load balancer
- Consider GPU acceleration cho production (latency giáº£m 5-10x)

## ğŸ› Troubleshooting

### Issue: "Connection refused to localhost:11434"
**Solution:** 
```bash
# Kiá»ƒm tra Ollama Ä‘ang cháº¡y
systemctl status ollama

# Hoáº·c start manually
ollama serve
```

### Issue: "Model not found"
**Solution:**
```bash
# Pull model láº¡i
ollama pull llama3.2:3b-instruct-fp16
ollama pull qwen2.5:1.5b-instruct-fp16
```

### Issue: "Response timeout"
**Solution:**
- TÄƒng `timeout` trong config (default: 30s)
- Kiá»ƒm tra CPU/RAM usage (cÃ³ thá»ƒ mÃ¡y Ä‘ang overload)
- Xem xÃ©t dÃ¹ng model nhá» hÆ¡n

### Issue: "Invalid JSON in response"
**Solution:**
- ÄÃ¢y lÃ  lá»—i phá»• biáº¿n vá»›i LLM generation
- Agent Ä‘Ã£ cÃ³ retry logic (max 2 retries)
- Náº¿u váº«n lá»—i, cÃ³ thá»ƒ tune prompt hoáº·c temperature

## ğŸ“š Documentation

- **[INTEGRATION_GUIDE.md](./INTEGRATION_GUIDE.md)**: HÆ°á»›ng dáº«n tÃ­ch há»£p vÃ o FastAPI backend
- **[TESTING_GUIDE.md](./TESTING_GUIDE.md)**: HÆ°á»›ng dáº«n testing vÃ  quality assurance
- **[PROMPT_TUNING.md](./PROMPT_TUNING.md)**: HÆ°á»›ng dáº«n customize prompts cho domain-specific

## ğŸ” Security Considerations

1. **Input Validation**: Validate táº¥t cáº£ inputs trÆ°á»›c khi gá»­i cho agents
2. **Output Sanitization**: Sanitize agent outputs trÆ°á»›c khi hiá»ƒn thá»‹ cho users
3. **Rate Limiting**: Implement rate limiting Ä‘á»ƒ trÃ¡nh abuse
4. **Logging**: Log táº¥t cáº£ agent calls (nhÆ°ng **KHÃ”NG** log sensitive data)
5. **Timeout**: LuÃ´n set timeout Ä‘á»ƒ trÃ¡nh hanging requests

## ğŸ¤ Contributing

Khi customize hoáº·c improve agents:

1. Test thoroughly vá»›i sample data
2. Measure performance impact
3. Document changes trong code comments
4. Update relevant documentation
5. Add unit tests cho new functionality

## ğŸ“ License

Internal use only - DATN Project

## ğŸ‘¥ Authors

- **Developer**: [Your Name]
- **Project**: DATN - AI Recruitment Platform
- **Epic**: Epic 8 - Virtual AI Interview Room
- **Date**: January 2026

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», check cÃ¡c tÃ i liá»‡u sau:
1. README.md (this file)
2. INTEGRATION_GUIDE.md
3. TESTING_GUIDE.md
4. Ollama documentation: https://ollama.com/docs

Hoáº·c raise issue trong project repository.
